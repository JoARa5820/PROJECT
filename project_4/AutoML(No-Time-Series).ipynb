{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 코드 사용법 :\n",
    "# 1. 해당 코드 내에서는 이상값에 대한 처리를 진행하지 않음\n",
    "# 2. 사용 파일의 형식은 'csv'를 기준으로 진행\n",
    "\n",
    "## 코드 내에서 진행되는 독립변수의 전처리 및 변수 선택 과정\n",
    "# (1) 독립변수에 대해 표준화\n",
    "# - StandardScaler : 평균은 0, 표준편차는 1로 변환\n",
    "# - Normalization : 최소값을 0, 최대값을 1로 변환 (0~1 사이의 값으로 변환) : 이상값에 영향 받으므로 이상값 처리 후 사용\n",
    "# - RobustScaler : 중앙값을 0, IQR(1분위수~3분위수)을 1로 변환 : 이상값의 영향을 최소화 시키는 표준화 방법\n",
    "# (2) 상관분석\n",
    "# - 상관계수 값의 기준을 본인이 설정 (y와 x변수간의 단일 상관계수 값이 'corr_stand_val' 이상인 x변수만 입력변수로 사용)\n",
    "# (3) Null 값이 포함된 변수 제외\n",
    "# - 변수 값 중 Null 값이 존재하는 경우, 해당 변수를 입력변수 목록에서 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AutoML 설명\n",
    "# (1) AutoML은 총 20여 개의 머신러닝 및 딥러닝 모델을 포함한 알고리즘임\n",
    "# (2) 학습 시 해당 데이터에 가장 적합한 모델을 선택하며, 파라미터 또한 최적화 된 값을 선택해줌\n",
    "# (3) AutoML은 머신러닝 기반의 모형이기 때문에, 통계적 모형인 회귀 모형과는 달리 다중공선성 등의 과정을 진행하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 0. 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터프레임 출력 옵션\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#지수표현\n",
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 1. 입력값 기입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 기본 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data_folder : 원본데이터 위치(폴더명)\n",
    "## save_folder : 결과 저장 위치(폴더명)\n",
    "## file_nm : 파일명\n",
    "## y_colnm : y 컬럼명\n",
    "\n",
    "data_folder = 'data'\n",
    "save_folder = 'result'\n",
    "file_nm = ['no_ts_data']\n",
    "y_colnm = ['y_col']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 표준화 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 독립변수(x)에 대하여 표준화 진행 시 원하는 표준화 기법 선택 (입력 안하면 표준화 진행 X)\n",
    "# 1 : 표준화1(StandardScaler) : 평균 = 0 / 표준편차 = 1\n",
    "# 2 : 표준화2(Normalization) : MinMaxScaler : 최소값 0 ~ 최대값 1 : 이상값에 영향 받음\n",
    "# 3 : 표준화3(RobustScaler) : 중앙값 = 0 / IQR(1분위(25%) ~ 3분위(75%)) = 1 \n",
    "select_scaler = 1  # (1, 2, 3) 중 택 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 상관분석 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상관계수 값 설정 (y와 x변수간의 단일 상관계수 값이 'corr_stand_val' 이상인 x변수만 입력변수로 사용)\n",
    "# 입력변수 : 모델링에 이용되는 변수\n",
    "corr_stand_val = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 2. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 정보 통합\n",
    "file_info = pd.DataFrame(file_nm).rename(columns = {0:'file_nm'})\n",
    "file_info['y_colnm'] = y_colnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_312\"; OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07); OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n",
      "  Starting server from /home/lime/.local/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpeyktbdaj\n",
      "  JVM stdout: /tmp/tmpeyktbdaj/h2o_lime_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpeyktbdaj/h2o_lime_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Seoul</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.34.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 18 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_lime_tw99l3</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4.271 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.10 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Asia/Seoul\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.34.0.7\n",
       "H2O_cluster_version_age:    1 month and 18 days\n",
       "H2O_cluster_name:           H2O_from_python_lime_tw99l3\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4.271 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  1\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.10 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "H2O session _sid_8bc6 closed.\n"
     ]
    }
   ],
   "source": [
    "# h2o 호출\n",
    "h2o.init(nthreads=1)\n",
    "\n",
    "for file_num in range(len(file_info)):\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    # 분석 정보 호출\n",
    "    file_nm = file_info['file_nm'][file_num]\n",
    "    y_colnm = file_info['y_colnm'][file_num]\n",
    "\n",
    "    # 데이터 호출\n",
    "    data = pd.read_csv(data_folder + '/' + file_nm + '.csv', dtype='str', encoding = 'utf-8')\n",
    "\n",
    "    # 독립변수 컬럼명 정의 : x_colnm\n",
    "    tot_colnm = list(data.columns)                         # 전체 컬럼명\n",
    "    x_colnm = list(set(tot_colnm).difference(set([y_colnm])))  # 독립변수 컬럼명\n",
    "\n",
    "    # 데이터 형 변환(str -> float)\n",
    "    data[[y_colnm] + x_colnm] = data[[y_colnm] + x_colnm].astype('float')\n",
    "\n",
    "    # (train / valid) 데이터 분할\n",
    "    x_data = data[x_colnm]\n",
    "    y_data = data[[y_colnm]]\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(x_data, y_data, test_size = 0.2, shuffle = True, random_state = 1234)\n",
    "    train_x.reset_index(drop=True, inplace=True)\n",
    "    valid_x.reset_index(drop=True, inplace=True)\n",
    "    train_y.reset_index(drop=True, inplace=True)\n",
    "    valid_y.reset_index(drop=True, inplace=True)\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    ## 표준화 수행\n",
    "\n",
    "    # StandardScaler : 평균 0, 표준편차 1\n",
    "    if select_scaler == 1:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()   \n",
    "        mody_train_x = pd.DataFrame(scaler.fit_transform(train_x), columns = list(train_x.columns))\n",
    "        mody_valid_x = pd.DataFrame(scaler.transform(valid_x), columns = list(valid_x.columns))\n",
    "\n",
    "    # Normalization : MinMaxScaler : 최소값 0 ~ 최대값 1\n",
    "    elif select_scaler == 2:\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        mody_train_x = pd.DataFrame(scaler.fit_transform(train_x), columns = list(train_x.columns))\n",
    "        mody_valid_x = pd.DataFrame(scaler.transform(valid_x), columns = list(valid_x.columns))\n",
    "\n",
    "    # RobustScaler : 중앙값 0, IQR(1분위(25%) ~ 3분위(75%)) 1 : 이상치(outlier) 영향 최소화 / 더 넓게 분포\n",
    "    elif select_scaler == 3:\n",
    "        from sklearn.preprocessing import RobustScaler\n",
    "        scaler = RobustScaler()\n",
    "        mody_train_x = pd.DataFrame(scaler.fit_transform(train_x), columns = list(train_x.columns))\n",
    "        mody_valid_x = pd.DataFrame(scaler.transform(valid_x), columns = list(valid_x.columns))\n",
    "\n",
    "    # 표준화 수행 X\n",
    "    else:\n",
    "        mody_train_x = train_x\n",
    "        mody_valid_x = valid_x\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    # inf / -inf 값을 null 처리\n",
    "    mody_train_x = mody_train_x.replace([np.inf, -np.inf], np.nan)\n",
    "    mody_valid_x = mody_valid_x.replace([np.inf, -np.inf], np.nan)        \n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    # 모델에 사용할 train, valid 데이터셋\n",
    "    mdl_train_data = pd.concat([train_y, mody_train_x], axis = 1)\n",
    "    mdl_valid_data = mody_valid_x\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    ## 독립변수 선택\n",
    "\n",
    "    # 1. 상관분석 : 상관분석은 train 데이터셋에 대해서만 진행 (test 데이터셋 이용 X)\n",
    "    corr = mdl_train_data.corr(method = 'pearson')  # default는 'pearson'\n",
    "    corr = corr.reset_index().rename(columns = {'index':'COLNM'})\n",
    "    corr = corr.loc[corr['COLNM'] != y_colnm,]\n",
    "    corr = corr[corr[y_colnm] >= corr_stand_val]\n",
    "\n",
    "    # 2. 상관분석 결과로 선택된 독립변수 목록\n",
    "    mdl_x_colnm = list(corr['COLNM'])\n",
    "\n",
    "    # 3. 독립변수 목록 중 null값이 없는 독립변수만 선택\n",
    "    train_na_col = []\n",
    "    for col in mdl_valid_data.columns:\n",
    "        if len(mdl_train_data.loc[mdl_train_data[col].isna(),]) != 0:\n",
    "            train_na_col.append(col)\n",
    "\n",
    "    test_na_col = []\n",
    "    for col in mdl_valid_data.columns:\n",
    "        if len(mdl_valid_data.loc[mdl_valid_data[col].isna(),]) != 0:\n",
    "            test_na_col.append(col)\n",
    "\n",
    "    tot_na_col = list(set(train_na_col + test_na_col))  # null값이 있는 독립변수들\n",
    "    mdl_x_colnm = list(set(mdl_x_colnm).difference(set(tot_na_col)))  # 모델에 사용할 독립변수들(상관분석 결과 - null값이 있는 변수)\n",
    "\n",
    "    if len(mdl_x_colnm) == 0:  # 모델에 사용할 독립변수의 수가 0이면 => 기본 독립변수 중 null값이 없는 변수를 선택 \n",
    "        mdl_x_colnm = x_colnm\n",
    "        mdl_x_colnm = list(set(mdl_x_colnm).difference(set(tot_na_col)))  # 모델에 사용할 독립변수들\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    # h2o 데이터프레임 형식으로 변환\n",
    "    h2o_train_data = h2o.H2OFrame(mdl_train_data)\n",
    "    h2o_valid_data = h2o.H2OFrame(mdl_valid_data)\n",
    "\n",
    "    ## 모델 생성\n",
    "    model = H2OAutoML(max_models=20, max_runtime_secs=10, seed=1234)\n",
    "    model.train(x = mdl_x_colnm, y = y_colnm,\n",
    "                training_frame = h2o_train_data)  # x : 독립변수 / y : 종속변수 / training_frame : 학습데이터 / 모델 검증은 pass\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    # # View the AutoML Leaderboard\n",
    "    # lb = model.leaderboard\n",
    "    # lb.head(rows = 10)  # 가장 성능 좋은 모델 top 10개 확인\n",
    "    # model.leader  # 리더보드 값 확인 : The leader model is stored here\n",
    "\n",
    "    # ## 모델 조사\n",
    "    # m = model.leader  # Get the best model using the metric\n",
    "    # m = model.get_best_model()  # this is equivalent to\n",
    "\n",
    "    ## AutoML 출력\n",
    "    # Get leaderboard with all possible columns\n",
    "    lb = h2o.automl.get_leaderboard(model, extra_columns = \"ALL\")  # lb : top 10개 모델에 대한 리더보드 확인\n",
    "    save_lb = lb.as_data_frame()  # pandas 데이터프레임으로 형변환\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "    ## 예측 수행\n",
    "    pred = model.predict(h2o_valid_data)\n",
    "\n",
    "    ## h2o 데이터프레임을 pandas 데이터프레임으로 변환\n",
    "    pred = h2o.as_list(pred, use_pandas=True)  # 또는 pred.as_data_frame()\n",
    "    pred.rename(columns={'predict':'PREDICT'}, inplace=True)\n",
    "    # -------------------------------------------------------------------------------------------------------------- #\n",
    "    ## 결과값 정리\n",
    "    rslt = pd.concat([pred, valid_y], axis = 1)\n",
    "    rslt['PREDICT'] = round(rslt['PREDICT'],4)\n",
    "    rslt[y_colnm] = round(rslt[y_colnm],4)\n",
    "    # rslt['BEST_MDL'] = save_lb['model_id'][0]  # 최적 모델명\n",
    "    # rslt['mdl_x_colnm'] = str(mdl_x_colnm)     # 모델링에 사용된 입력변수 목록\n",
    "    rslt.rename(columns = {'y_col':'REAL'}, inplace=True)\n",
    "\n",
    "    rslt.to_csv(save_folder + '/result_' + file_nm + '.csv', index=False, encoding = 'utf-8')\n",
    "\n",
    "    # h2o 종료\n",
    "    h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 모델 생성 시간 :  0.27679 분 소요\n"
     ]
    }
   ],
   "source": [
    "print('총 모델 생성 시간 : ', str((time.time() - total_start_time)/60)[:7]+' 분 소요')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
