{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffdf6b3",
   "metadata": {},
   "source": [
    "# 벡터자기회귀(VAR) 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4152c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VAR모형의 가장 큰 특징\n",
    "# (1) 충격반응분석(impulse response analysis)을 통하여 어떠한 한 변수의 변화가 내생변수에 미치는 동태적 반응을 파악할 수 있다.\n",
    "# (2) 분산분해(variance decomposition)를 통하여 각 내생변수의 변동이 전체변동에 기여한 부분의 상대적 크기를 분석할 수 있다.\n",
    "# (3) 경제이론 보다는 실제 자료에서 도출된 결과를 분석한다.\n",
    "# (4) 그러나 VAR모형은 사용되는 변수 및 표본기간, 시차길이를 따라서 결과가 달라질 수 있다는 약점이 있다.\n",
    "# (VAR 모형의 예시: 환율과 수출 물가에 의한 상품수출모형을 설정하여 모형 설정과정과 해석방법 등을 설명)\n",
    "\n",
    "# # 설명\n",
    "# 벡터자기회귀모형은 일변량 자기회귀모형을 다변량 자기회귀모형으로 확정시킨 모형으로\n",
    "# 예측 및 내생변수의 변화에 따른 효과분석 등과 관련하여 자주 활용되고 있다.\n",
    "# 전통적인 회귀모형에 의한 구조방정식모형은 변수간의 인과관계를 통하여 종속변수 Y를 몇 개의 설명 변수 {X1, X2, …}에 의해서 설명하고 있다.\n",
    "# 그러나 회귀모형에서는 설명변수의 영향이 시간 t가 변하더라도 항상 일정하다는 가정을 하고 있어\n",
    "# 구조적 변화가 급속히 진행되어 설명변수의 영향이 변한 경우 이를 적절히 반영하지 못한다는 약점이 있다.\n",
    "# 또한 구조모형(structuremodel)은 경제이론에 의해서 모형을 구축하고 있어\n",
    "# 변수선택 및 모형의 내․외생변수의 선정이 모형 설계자의 주관에 의해서 결정된다는 단점이 있다.\n",
    "# 따라서 이러한 시간에 대한 경직성과 주관성을 극복할 수 있는 방법이 Box and Jenkins(1976)의 ARIMA모형이라고 할 수 있다.\n",
    "# ARIMA모형은 현재의 관측치 Zt는 과거의 어떠한 규칙성에 의해서 재현되며,\n",
    "# 이러한 규칙성은 미래에도 유지된다고 가정하고 미래를 예측하고자 했다.\n",
    "# 이러한 방법은 모형 설정이 용이한 반면 변수들 사이의 상호작용을 무시하고 있어 일변량분석이라는 한계에 부딪치게 된다.\n",
    "# 이들 회귀모형과 시계열분석의 한계를 보완한 모형이 Sims(1980)의 VAR모형이라 할 수 있다.\n",
    "# [출처 : 통계청『통계분석연구』제2권 제1호(‘97.봄)23-56 / 벡터자기회귀(VAR)모형의 이해 / Vector Autoregressive Model: VAR / 문권순]\n",
    "# => 모든 변수는 시스템 안의 다른 모든 변수에 영향을 준다는 가정을 하기 때문에, 추정한 계수를 해석하는 것이 어렵다.\n",
    "\n",
    "# # 정리\n",
    "# VAR 모형은 종속변수와 독립변수가 서로 영향을 주고 받는다는 가정하에 사용되기 때문에\n",
    "# train data(종속변수 + 독립변수)를 이용하여 모델을 학습하고 해당 train data(종속변수 + 독립변수)를 이용하여 예측값을 생성함\n",
    "# 즉, 독립변수와 종속변수가 서로 영향을 주는 관계이기 때문에 독립변수와 종속변수가 구분되어 있다고 할 수 없음\n",
    "# => 독립변수가 종속변수에 영향을 주고, 종속변수가 독립변수에 영향을 주는 관계일 때 사용하는 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b27103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 차분(differencing)\n",
    "# - 연이은 관측값들의 차이를 계산하는 것\n",
    "# - 로그 같은 변환은 시계열의 분산 변화를 일정하게 만드는데 도움이 될 수 있음\n",
    "# - 차분(differencing)은 시계열의 수준에서 나타나는 변화를 제거하여 시계열의 평균 변화를 일정하게 만드는데 도움이 될 수 있음\n",
    "# - 결과적으로 추세나 계절성이 제거(또는 감소)됨\n",
    "\n",
    "# # 정상성(Stationary)\n",
    "# - 정상성(stationarity)을 나타내는 시계열은 '시계열의 특징'이 '해당 시계열이 관측된 시간에 무관'\n",
    "# - 즉, {Yt}가 정상성을 나타내는 시계열이라면, 모든 s에 대해 (Yt, ..., Yt+s)의 분포에 t가 무관함\n",
    "# - 이 말은 추세나 계절성이 있는 시계열은 정상성을 나타내는 시계열이 아니라는 점(추세와 계절성은 서로 다른 시간에 시계열의 값에 영향을 주기 때문)\n",
    "# - 그래서 정상성을 나타내는 시계열을 '백색잡음(white noise)'라고 하기도 함(언제 관찰하든, 시간이 어떻든 똑같이 보이기 때문)\n",
    "# - 주기(cycle)이 있긴 하지만 이 주기가 불규칙적이기 때문에 정상성이 있다고 본다고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa549a35",
   "metadata": {},
   "source": [
    "----------\n",
    "# 0. 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16393c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터프레임 출력 옵션\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#지수표현\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "# # 그래프 폰트\n",
    "# font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# rc('font', family=font_name)\n",
    "# plt.rc('font', family='Malgun Gothic')\n",
    "# plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "# plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ec71f",
   "metadata": {},
   "source": [
    "----------\n",
    "# 1. 입력값 기입"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f45cd8",
   "metadata": {},
   "source": [
    "## 1-1. 기본 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed52245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'    # 원본데이터 위치(폴더명)\n",
    "save_folder = 'result'  # 결과 저장 위치(폴더명)\n",
    "file_nm = 'ts_data(jena_climate_2009_2016)'  # 원본파일명(csv 파일)\n",
    "sv_file_nm = 'result_ts_data(jena_climate_2009_2016)'  # 결과파일명(csv 파일)\n",
    "file_encode = 'utf-8'     # 원본데이터의 encoding\n",
    "sv_file_encode = 'utf-8'  # 결과데이터의 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756ab52",
   "metadata": {},
   "source": [
    "## 1-2. 표준화 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60858d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 독립변수(x)에 대하여 표준화 진행 시 원하는 표준화 기법 선택 (입력 안하면 표준화 진행 X)\n",
    "# 1 : 표준화1(StandardScaler) : 평균 = 0 / 표준편차 = 1\n",
    "# 2 : 표준화2(Normalization) : MinMaxScaler : 최소값 0 ~ 최대값 1 : 이상값에 영향 받음\n",
    "# 3 : 표준화3(RobustScaler) : 중앙값 = 0 / IQR(1분위(25%) ~ 3분위(75%)) = 1 \n",
    "select_scaler = 1  # (1, 2, 3) 중 택 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea1c2b6",
   "metadata": {},
   "source": [
    "## 1-3. 상관분석 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26056bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상관계수 값 설정 (y와 x변수간의 단일 상관계수 값이 'corr_stand_val' 이상인 x변수만 입력변수로 사용)\n",
    "# 입력변수 : 모델링에 이용되는 변수\n",
    "corr_stand_val = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9946510a",
   "metadata": {},
   "source": [
    "## 1-4. test set 비율 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5d228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋 중 test_per 비율만큼 오차율 계산\n",
    "test_per = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddfb82",
   "metadata": {},
   "source": [
    "----\n",
    "# 2. 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9302d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아래의 데이터를 저장하여 사용함\n",
    "# import tensorflow as tf\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "# mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "# zip_path = tf.keras.utils.get_file(\n",
    "#   origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "#   fname='jena_climate_2009_2016.csv.zip',\n",
    "#   extract=True)\n",
    "# csv_path, _ = os.path.splitext(zip_path)\n",
    "# df = pd.read_csv(csv_path)\n",
    "# df.to_csv('ts_data(jena_climate_2009_2016).csv', index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3464e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 컬럼 설명\n",
    "# Index   Features           Format                  Description\n",
    "# 1       Date Time          01.01.2009 00:10:00     Date-time reference\n",
    "# 2       p (mbar)           996.52                  The pascal SI derived unit of pressure used to quantify internal pressure. Meteorological reports typically state atmospheric pressure in millibars.\n",
    "# 3       T (degC)           -8.02                   Temperature in Celsius\n",
    "# 4       Tpot (K)           265.4                   Temperature in Kelvin\n",
    "# 5       Tdew (degC)        -8.9                    Temperature in Celsius relative to humidity. Dew Point is a measure of the absolute amount of water in the air, the DP is the temperature at which the air cannot hold all the moisture in it and water condenses.\n",
    "# 6       rh (%)             93.3                    Relative Humidity is a measure of how saturated the air is with water vapor, the %RH determines the amount of water contained within collection objects.\n",
    "# 7       VPmax (mbar)       3.33                    Saturation vapor pressure\n",
    "# 8       VPact (mbar)       3.11                    Vapor pressure\n",
    "# 9       VPdef (mbar)       0.22                    Vapor pressure deficit\n",
    "# 10      sh (g/kg)          1.94                    Specific humidity\n",
    "# 11      H2OC (mmol/mol)    3.12                    Water vapor concentration\n",
    "# 12      rho (g/m ** 3)     1307.75                 Airtight\n",
    "# 13      wv (m/s)           1.03                    Wind speed\n",
    "# 14      max. wv (m/s)      1.75                    Maximum wind speed\n",
    "# 15      wd (deg)           152.3                   Wind direction in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01200f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출 및 필요 컬럼 정리\n",
    "data = pd.read_csv(data_folder + '/' + file_nm + '.csv', encoding = file_encode)\n",
    "data.columns = list(pd.Series(list(data.columns)).map(lambda x : x.replace(' ','')))\n",
    "\n",
    "# (날짜변수/종속변수/독립변수) 컬럼명 정의 : x_colnm\n",
    "tm_colnm = 'DateTime'\n",
    "y_colnm = 'T(degC)'\n",
    "x_colnm = list(set(data.columns).difference({y_colnm}).difference({tm_colnm}))\n",
    "\n",
    "# Y(t+1)은 X(t)들에 의해 영향을 받음\n",
    "data = pd.concat([data[y_colnm].shift(-1), data[x_colnm]], axis = 1)\n",
    "\n",
    "# 데이터 형 변환(str -> float)\n",
    "data[[y_colnm] + x_colnm] = data[[y_colnm] + x_colnm].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f25634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 임시(데이터 건수 줄여서 테스트 진행)\n",
    "data = data.iloc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33150658-760b-4ee5-9a67-19f8314b656f",
   "metadata": {},
   "source": [
    "------\n",
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10ff0e",
   "metadata": {},
   "source": [
    "## 3-1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c32552",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 표준화 수행\n",
    "\n",
    "# StandardScaler : 평균 0, 표준편차 1\n",
    "if select_scaler == 1:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    data[x_colnm] = pd.DataFrame(scaler.fit_transform(data[x_colnm]), columns = list(data[x_colnm].columns))\n",
    "\n",
    "# Normalization : MinMaxScaler : 최소값 0 ~ 최대값 1\n",
    "elif select_scaler == 2:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    data[x_colnm] = pd.DataFrame(scaler.fit_transform(data[x_colnm]), columns = list(data[x_colnm].columns))\n",
    "\n",
    "# RobustScaler : 중앙값 0, IQR(1분위(25%) ~ 3분위(75%)) 1 : 이상치(outlier) 영향 최소화 / 더 넓게 분포\n",
    "elif select_scaler == 3:\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    scaler = RobustScaler()\n",
    "    data[x_colnm] = pd.DataFrame(scaler.fit_transform(data[x_colnm]), columns = list(data[x_colnm].columns))\n",
    "\n",
    "# 표준화 수행 X\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435d29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inf / -inf 값을 null 처리\n",
    "data = data.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200043ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 독립변수 선택\n",
    "\n",
    "# 1. 상관분석 : 상관분석은 train 데이터셋에 대해서만 진행 (test 데이터셋 이용 X)\n",
    "corr = data.corr(method = 'pearson')  # default는 'pearson'\n",
    "corr = corr.reset_index().rename(columns = {'index':'COLNM'})\n",
    "corr = corr.loc[corr['COLNM'] != y_colnm,]\n",
    "corr = corr[corr[y_colnm] >= corr_stand_val]\n",
    "\n",
    "# 2. 상관분석 결과로 선택된 독립변수 목록\n",
    "mdl_x_colnm = list(corr['COLNM'])\n",
    "\n",
    "# 3. 독립변수 목록 중 null값이 없는 독립변수만 선택\n",
    "na_col = []\n",
    "for col in data.columns:\n",
    "    if len(data.loc[data[col].isna(),]) != 0:\n",
    "        na_col.append(col)\n",
    "\n",
    "mdl_x_colnm = list(set(mdl_x_colnm).difference(set(na_col)))  # 모델에 사용할 독립변수들(상관분석 결과 - null값이 있는 변수 제거)\n",
    "\n",
    "if len(mdl_x_colnm) == 0:  # 모델에 사용할 독립변수의 수가 0이면 => 기본 독립변수 중 null값이 없는 변수를 선택 \n",
    "    mdl_x_colnm = x_colnm\n",
    "    mdl_x_colnm = list(set(mdl_x_colnm).difference(set(na_col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e15615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 된 데이터셋\n",
    "mody_data = data[[y_colnm] + mdl_x_colnm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8392f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data와 test data 분리\n",
    "test_cnt = int(round((len(mody_data) * test_per),0))  # test set 건수 = 전체 데이터셋 * test_per(비율)\n",
    "train_data = mody_data[:len(mody_data) - test_cnt].reset_index(drop=True)\n",
    "test_data = mody_data[-test_cnt:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58facd7",
   "metadata": {},
   "source": [
    "## 3-2. 정상성 확인 (ADF-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5519757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 정상성 확인 (ADF-Test)\n",
    "# 귀무가설 : 정상성이 없다 = 시계열 흐름이 불규칙하다\n",
    "# p-value가 0.05보다 크면 귀무가설을 기각할 수 없음 = 정상성이 없다 = 시계열 흐름이 불규칙하다\n",
    "ADF_test_statistic = []\n",
    "p_value = []\n",
    "for i in train_data.columns[1:]:\n",
    "    adfuller_test = adfuller(train_data[i], autolag= \"AIC\")\n",
    "    ADF_test_statistic.append(adfuller_test[0])\n",
    "    p_value.append(adfuller_test[1])\n",
    "\n",
    "ADF_col_nm = pd.DataFrame(train_data.columns[1:]).rename(columns = {0:'col_nm'})\n",
    "ADF_test_statistic = pd.DataFrame(ADF_test_statistic).rename(columns = {0:'ADF_test_statistic'})\n",
    "p_value = pd.DataFrame(p_value).rename(columns = {0:'p_value'})\n",
    "\n",
    "ADF_test = pd.concat([ADF_col_nm, ADF_test_statistic, p_value], axis = 1)  # 전체 ADF_test 결과 출력\n",
    "\n",
    "# # ADF_test 결과, 정상성을 만족하지 않는 컬럼 목록 : 차분 필요\n",
    "diff_list = list(ADF_test.loc[ADF_test['p_value'] >= 0.05,'col_nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2f6b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_nm</th>\n",
       "      <th>ADF_test_statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tpot(K)</td>\n",
       "      <td>-1.77611</td>\n",
       "      <td>0.39239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sh(g/kg)</td>\n",
       "      <td>-0.94497</td>\n",
       "      <td>0.77280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VPmax(mbar)</td>\n",
       "      <td>-1.46610</td>\n",
       "      <td>0.55021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H2OC(mmol/mol)</td>\n",
       "      <td>-0.94971</td>\n",
       "      <td>0.77116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tdew(degC)</td>\n",
       "      <td>-0.94636</td>\n",
       "      <td>0.77232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VPact(mbar)</td>\n",
       "      <td>-0.93889</td>\n",
       "      <td>0.77490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           col_nm  ADF_test_statistic  p_value\n",
       "0         Tpot(K)            -1.77611  0.39239\n",
       "1        sh(g/kg)            -0.94497  0.77280\n",
       "2     VPmax(mbar)            -1.46610  0.55021\n",
       "3  H2OC(mmol/mol)            -0.94971  0.77116\n",
       "4      Tdew(degC)            -0.94636  0.77232\n",
       "5     VPact(mbar)            -0.93889  0.77490"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADF_test 결과 확인\n",
    "ADF_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a17cd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상성을 만족하지 않는 컬럼의 경우, 차분한 후 다시 정상성 확인\n",
    "if len(diff_list) != 0:\n",
    "\n",
    "    # 차분 데이터 생성\n",
    "    diff_data = train_data[diff_list].diff(1).dropna()\n",
    "\n",
    "    # 차분 데이터의 정상성 확인 (ADF-Test)\n",
    "    ADF_test_statistic = []\n",
    "    p_value = []\n",
    "    for i in diff_data.columns:\n",
    "        adfuller_test = adfuller(diff_data[i], autolag= \"AIC\")\n",
    "        ADF_test_statistic.append(adfuller_test[0])\n",
    "        p_value.append(adfuller_test[1])\n",
    "\n",
    "    ADF_col_nm = pd.DataFrame(diff_data.columns[1:]).rename(columns = {0:'col_nm'})\n",
    "    ADF_test_statistic = pd.DataFrame(ADF_test_statistic).rename(columns = {0:'ADF_test_statistic'})\n",
    "    p_value = pd.DataFrame(p_value).rename(columns = {0:'p_value'})\n",
    "\n",
    "    ADF_test = pd.concat([ADF_col_nm, ADF_test_statistic, p_value], axis = 1)\n",
    "\n",
    "    # # ADF_test 결과, 정상성을 만족하지 않는 컬럼 목록 : 차분 필요\n",
    "    diff_list_1 = list(ADF_test.loc[ADF_test['p_value'] >= 0.05,'col_nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6965ba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1차 차분 외 추가로 차분해야하는 컬럼 목록\n",
    "diff_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce0d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '1차 차분' 진행 후 차분으로 인해 생성된 null값 제거 (여기서는 1차 차분만 진행 - 필요에 따라 추가 차분 코드 작성)\n",
    "train_data[diff_list] = train_data[diff_list].diff(1)\n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5783b",
   "metadata": {},
   "source": [
    "## 3-3. VAR 모형 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2491dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAR 모형의 최적 순서 탐색 : (1) AIC 값은 낮을수록 좋음 / (2) Grid-Search를 수행하여 최소 AIC를 만족하는 최적의 p를 탐색\n",
    "model = VAR(train_data)\n",
    "\n",
    "fit_param = []\n",
    "result_aic = []\n",
    "for p in range(1,len(train_data) + 1):\n",
    "    try :\n",
    "        fitted_model = model.fit(p)  # 모델 생성\n",
    "        fit_param.append(p)\n",
    "        result_aic.append(fitted_model.aic)\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "fit_param = pd.DataFrame(fit_param, columns = ['fit_param'])\n",
    "result_aic = pd.DataFrame(result_aic, columns = ['result_aic'])\n",
    "fit_param_df = pd.concat([fit_param,result_aic], axis = 1)\n",
    "\n",
    "# 최적의 p 값 도출 : fit_param_val\n",
    "fit_param_val = list(fit_param_df.loc[fit_param_df['result_aic'] == fit_param_df['result_aic'].min(), 'fit_param'])[0]\n",
    "\n",
    "# # 최적 p 값 그래프로 확인 (필요시 확인)\n",
    "# plt.plot(fit_param_df['fit_param'], fit_param_df['result_aic'])\n",
    "# plt.plot(fit_param_df['fit_param'][0:200], fit_param_df['result_aic'][0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d6a614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 생성(model fitting)\n",
    "fitted_model = model.fit(fit_param_val)\n",
    "# fitted_model.summary()  # 모델 fitting 결과 (필요시 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bc8242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagged_values 표현식 : train_data[-fit_param_val:].values 또는 np.array(train_data[-fit_param_val:])\n",
    "lagged_values = np.array(train_data[-fit_param_val:])  # 예측을 위해 사용할 데이터\n",
    "predict = pd.DataFrame(fitted_model.forecast(lagged_values, steps = test_cnt), columns = list(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25caa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "df_pred = predict[[y_colnm]].rename(columns = {y_colnm:'pred'})    # pred 값\n",
    "df_real = test_data[[y_colnm]].rename(columns = {y_colnm:'real'})  # real 값\n",
    "\n",
    "result = pd.concat([df_pred, df_real], axis = 1)\n",
    "result['error_rate'] = ((result['pred'] - result['real'])/result['real']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d0b263f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "      <th>error_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.30600</td>\n",
       "      <td>-11.07000</td>\n",
       "      <td>-6.90153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.82224</td>\n",
       "      <td>-11.33000</td>\n",
       "      <td>-13.30764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.43270</td>\n",
       "      <td>-11.90000</td>\n",
       "      <td>-20.73360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.01151</td>\n",
       "      <td>-12.43000</td>\n",
       "      <td>-27.50197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.34349</td>\n",
       "      <td>-12.47000</td>\n",
       "      <td>-33.09153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-17.35102</td>\n",
       "      <td>-9.30000</td>\n",
       "      <td>86.57007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1042.24079</td>\n",
       "      <td>-9.89000</td>\n",
       "      <td>-10638.32949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-605.37363</td>\n",
       "      <td>-10.44000</td>\n",
       "      <td>5698.59797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-1217.22466</td>\n",
       "      <td>-10.83000</td>\n",
       "      <td>11139.37821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>763.20337</td>\n",
       "      <td>-10.79000</td>\n",
       "      <td>-7173.24721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred      real   error_rate\n",
       "0     -10.30600 -11.07000     -6.90153\n",
       "1      -9.82224 -11.33000    -13.30764\n",
       "2      -9.43270 -11.90000    -20.73360\n",
       "3      -9.01151 -12.43000    -27.50197\n",
       "4      -8.34349 -12.47000    -33.09153\n",
       "..          ...       ...          ...\n",
       "195   -17.35102  -9.30000     86.57007\n",
       "196  1042.24079  -9.89000 -10638.32949\n",
       "197  -605.37363 -10.44000   5698.59797\n",
       "198 -1217.22466 -10.83000  11139.37821\n",
       "199   763.20337 -10.79000  -7173.24721\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29f8c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "result.to_csv(save_folder + '/' + sv_file_nm + '.csv', index=False, encoding = sv_file_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173729bf-2ed9-45e7-822e-7313ece1de28",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
